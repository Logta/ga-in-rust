# 戦略ガイド

このドキュメントでは、GA Prisoner's Dilemmaで実装されている各戦略の詳細な説明と理論的背景を提供します。

## 目次

1. [基本戦略](#基本戦略)
2. [直接互恵戦略](#直接互恵戦略)
3. [間接互恵戦略](#間接互恵戦略)
4. [戦略の選択指針](#戦略の選択指針)
5. [理論的背景](#理論的背景)

## 基本戦略

### ルーレット選択 (roulette)

**概要**: DNAの1の個数に基づく確率的協力戦略

**動作原理**:
- DNAビット列の1の個数を協力確率として使用
- 例：`110101`（4個の1）→ 4/6 = 66.7%の協力確率
- 毎回乱数を生成して行動を決定

**特徴**:
- ✅ 単純で理解しやすい
- ✅ 遺伝的アルゴリズムとの親和性が高い
- ❌ 相手の行動を考慮しない
- ❌ 学習効果がない

**適用場面**: 基本的なGA実験、ベースライン比較

### 閾値選択 (threshold)

**概要**: DNAの数値を閾値と比較する決定論的戦略

**動作原理**:
- DNAを2進数として解釈
- 値が最大値の半分未満なら協力、以上なら裏切り
- 例：`110101`（53）→ 53 < 32 → 裏切り

**特徴**:
- ✅ 決定論的で予測可能
- ✅ 計算が高速
- ❌ 柔軟性に欠ける
- ❌ 相手の行動を無視

**適用場面**: 決定論的戦略の比較研究、高速実行が必要な場合

## 直接互恵戦略

### Tit-for-Tat (tft)

**理論的背景**:
Robert Axelrodの囚人のジレンマトーナメントで優勝した戦略。「応報性」「寛容性」「親切性」「明快性」の4つの特徴を持つ。

**動作原理**:
1. 初回は常に協力
2. 2回目以降は相手の前回の行動を真似る
3. 協力 → 協力、裏切り → 裏切り

**数学的表現**:
```
C(t) = {
  Cooperate,           if t = 1
  O(t-1),             if t > 1
}
```
ここで、C(t)は時刻tでの自分の選択、O(t-1)は相手の前回の選択

**特徴**:
- ✅ 親切：まず協力する
- ✅ 応報性：裏切りには報復
- ✅ 寛容性：相手が協力に戻れば即座に協力
- ✅ 明快性：戦略が分かりやすい
- ❌ ノイズに弱い（誤解が連鎖する）

**期待される結果**:
- 相互協力の安定状態
- 初期世代では全員同点
- 長期的な協力の維持

### Generous Tit-for-Tat (gtft)

**理論的背景**:
TFTの改良版。Nowak & Sigmund (1992)により提案。ノイズのある環境での協力促進を目的とする。

**動作原理**:
1. 基本的にはTFTと同じ
2. 相手が裏切った場合、一定確率pで許して協力
3. 寛容率pは通常0.1〜0.3程度

**数学的表現**:
```
C(t) = {
  Cooperate,                    if t = 1
  Cooperate,                    if O(t-1) = Cooperate
  Cooperate with prob p,        if O(t-1) = Defect
  Defect with prob (1-p),       if O(t-1) = Defect
}
```

**特徴**:
- ✅ エラー回復：誤解からの回復が容易
- ✅ 協力促進：相互協力状態への復帰が早い
- ✅ ノイズ耐性：不完全情報下でも効果的
- ❌ 搾取されるリスク：常に許すと付け込まれる可能性

**パラメータ調整**:
- 低寛容率（p=0.1）：保守的、搾取されにくい
- 高寛容率（p=0.3）：積極的、協力促進効果大

### Pavlov (pavlov)

**理論的背景**:
「Win-Stay, Lose-Shift」原理に基づく。Nowak & Sigmund (1993)により詳細に研究された。強化学習の概念を戦略に応用。

**動作原理**:
1. 前回の対戦結果を評価
2. 高得点（3点以上）なら同じ行動を継続
3. 低得点（3点未満）なら行動を変更

**利得評価基準**:
- 3点以上：相互協力(3,3)、一方的搾取(5,0)
- 3点未満：相互裏切り(1,1)、一方的被搾取(0,5)

**数学的表現**:
```
C(t) = {
  Cooperate,                    if t = 1
  C(t-1),                       if Payoff(t-1) ≥ 3
  !C(t-1),                      if Payoff(t-1) < 3
}
```

**特徴**:
- ✅ 適応性：環境に応じて学習
- ✅ 自己修正：悪い結果から自動回復
- ✅ シンプル：理解しやすいルール
- ❌ 初期不安定：最初の数ラウンドで混乱する場合
- ❌ 複雑な環境：多対多の状況では効果が限定的

**実装上の注意**:
本実装では前回の対戦相手との個別履歴を保持し、相手ごとに独立して戦略を適用します。

## 間接互恵戦略

### 評判ベース戦略 (reputation)

**理論的背景**:
Nowak & Sigmund (1998)による間接互恵理論。社会的評判システムをモデル化し、「image scoring」の概念を基にした。

**動作原理**:
1. 各エージェントに評判スコア（-1.0〜1.0）を割り当て
2. 相手の評判が閾値以上なら協力、未満なら裏切り
3. 行動後に評判を更新（協力→+、裏切り→-）

**評判更新ルール**:
```
reputation(t) = (1-α) × reputation(t-1) + α × action_value
```
- α: 更新率（0.2推奨）
- action_value: 協力=+1, 裏切り=-1

**特徴**:
- ✅ 社会的：実際の人間社会に近い
- ✅ 第三者効果：直接関係ない相手の行動も影響
- ✅ 学習効果：評判は時間とともに更新
- ❌ 初期値依存：最初の評判設定が重要
- ❌ 計算コスト：全エージェントの評判管理が必要

### イメージスコアリング (image-scoring)

**理論的背景**:
Nowak & Sigmund (1998)の原論文による実装。各個体が他者の行動を観察し、独自の評価を形成する。

**動作原理**:
1. 未知の相手：初期協力確率に従って行動
2. 既知の相手：観察した評判に基づいて判断
3. より現実的な評判形成過程をモデル化

**特徴**:
- ✅ 現実的：実際の評判形成に近い
- ✅ 個別性：各個体が独自の評価を持つ
- ✅ 段階的学習：徐々に相手を知る過程
- ❌ 記憶コスト：多数の相手の情報を保持

### スタンディング戦略 (standing)

**理論的背景**:
Leimar & Hammerstein (2001)による「standing」概念。行動の文脈を考慮した道徳的判断をモデル化。

**動作原理**:
1. 相手の評判とstanding（地位）を区別
2. 悪い相手への裏切りは正当化される
3. 文脈を考慮した評判更新

**評判更新の文脈考慮**:
- 良い相手への協力：+評価
- 良い相手への裏切り：-評価
- 悪い相手への協力：+評価（やや小さめ）
- 悪い相手への裏切り：中立（正当化）

**特徴**:
- ✅ 道徳的：より洗練された判断
- ✅ 文脈考慮：状況に応じた評価
- ✅ 社会規範：「悪人には厳しく」を実装
- ❌ 複雑性：実装と理解が複雑
- ❌ パラメータ調整：多数のパラメータの最適化が必要

## 戦略の選択指針

### 研究目的別推奨戦略

**基本的なGA動作確認**:
- `roulette` または `threshold`
- シンプルで結果が予測しやすい

**協力進化の研究**:
- `tft` → `gtft` → `pavlov`
- 直接互恵の段階的理解

**社会的評判の研究**:
- `reputation` → `image-scoring` → `standing`
- 間接互恵の発展段階

**比較進化研究**:
- 全戦略を同一条件で比較
- 環境変化への適応性評価

### パラメータ設定の指針

**探索的研究**（新しい現象の発見）:
```bash
./target/debug/ga-sim -s reputation -g 10000 -p 100 -m 0.05
```

**詳細分析**（特定戦略の詳細研究）:
```bash
./target/debug/ga-sim -s tft -g 1000 -p 50 -r 100 -m 0.01
```

**高速スクリーニング**（多数の条件を素早く試す）:
```bash
./target/release/ga-sim -s pavlov -g 100 -p 20 -m 0.02
```

## 理論的背景

### 進化ゲーム理論

囚人のジレンマは進化ゲーム理論の中心的な研究対象です。本実装では以下の理論的概念を扱えます：

1. **進化的安定戦略 (ESS)**: 侵入不可能な戦略
2. **相関均衡**: 複数戦略の共存状態
3. **群選択**: グループ利益 vs 個体利益

### 協力の進化

Hamilton (1964)の包括適応度理論以来、協力の進化は生物学・社会科学の中心課題です：

1. **血縁選択**: 遺伝的関係による協力
2. **直接互恵**: 繰り返し相互作用による協力
3. **間接互恵**: 評判・地位による協力
4. **群選択**: グループ間競争による協力
5. **ネットワーク互恵**: 社会ネットワーク構造による協力

本実装では特に直接互恵（2）と間接互恵（3）に焦点を当てています。

### 実装上の革新

従来の理論研究との違い：

1. **遺伝的アルゴリズム**: 戦略の進化的動態をシミュレーション
2. **個体ベース**: エージェントレベルでの詳細な相互作用
3. **動的評判**: 時間変化する社会的評価システム
4. **比較可能性**: 同一フレームワークでの複数戦略比較

この戦略ガイドを参考に、研究目的に応じて適切な戦略を選択し、囚人のジレンマの豊かな動態を探索してください。